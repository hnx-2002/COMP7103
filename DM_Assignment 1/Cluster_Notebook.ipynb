{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Question 1\n",
    "<p style=\"font-size:22px;\">\n",
    "Run K-means on the datasets. And record its SSE\n",
    "</p>"
   ],
   "id": "a587d3dee5236222"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<p style=\"font-size:20px;\">\n",
    "First, read the data and delete the Norminal column, and convert the data to a numpy array\n",
    "</p>"
   ],
   "id": "d60b544869925ac7"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-05T09:08:43.734470Z",
     "start_time": "2024-11-05T09:08:43.362595Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data = pd.read_csv('clustering_data.csv')\n",
    "\n",
    "# delete the first column and convert to numpy array\n",
    "price_changes = data.iloc[:, 1:].values\n",
    "\n",
    "price_changes"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -4.7557   ,   4.00509  ,   3.58155  ,  -0.395257 ,   0.768624 ,\n",
       "          1.12594  ,  -0.237274 ,  -1.91728  ,   0.706794 ,   0.957592 ,\n",
       "         -0.0206825,   6.34668  ,  -2.82923  ,   1.68118  ,  -4.10586  ,\n",
       "          4.63801  ,   1.46898  ,   2.74809  ,  -0.0228676,   1.87709  ,\n",
       "         -0.70247  ,   2.44804  ,  -3.13752  ,  -1.13863  ,  -0.0651749],\n",
       "       [ -3.2019   ,   5.65488  ,  -1.44928  ,   0.693878 ,   0.574788 ,\n",
       "          1.50561  ,  -1.42566  ,   0.467675 ,  -2.90853  ,   0.0558659,\n",
       "         -3.65062  ,   0.99398  ,  -2.76886  ,  -1.29434  ,  -3.80463  ,\n",
       "          0.93633  ,   0.122649 ,   3.74037  ,  -0.92452  ,   4.33917  ,\n",
       "          3.06093  ,   4.88284  ,  -0.0691085,  -0.353045 ,   1.15721  ],\n",
       "       [ -0.55384  ,   1.92791  ,   0.529256 ,   1.80451  ,   2.05676  ,\n",
       "         -0.869652 ,  -3.18936  ,   3.37173  ,   3.67084  ,  -4.0242   ,\n",
       "         -0.9911   ,  -0.853207 ,  -1.21903  ,  -6.0285   ,  -3.45091  ,\n",
       "          2.06707  ,   1.0505   ,   3.03001  ,   1.43723  ,   2.81148  ,\n",
       "          3.47363  ,  -0.512765 ,   2.89227  ,  -0.83293  ,   0.903809 ],\n",
       "       [  0.431862 ,   3.48494  ,  -1.72414  ,  -1.84332  ,   0.304692 ,\n",
       "         -1.12285  ,  -3.83964  ,   0.0530786,  -3.76193  ,  -2.23312  ,\n",
       "         -0.0669344, -15.4229   ,  -5.73566  ,   0.285551 ,  -3.49608  ,\n",
       "          1.2894   ,   3.76249  ,   0.35545  ,  -1.18153  ,  -0.346021 ,\n",
       "          5.35117  ,   2.54279  ,  -0.480513 ,  -3.70793  ,  -2.35627  ],\n",
       "       [  3.81916  ,   1.97522  ,   0.       ,   1.99593  ,   1.56522  ,\n",
       "         -0.919448 ,  -1.00992  ,   2.8288   ,  -0.357277 ,  -2.21811  ,\n",
       "          4.9697   ,   3.72482  ,  -1.0338   ,  -3.17263  ,  -5.43437  ,\n",
       "          3.10559  ,  -0.18018  ,   3.00295  ,  -0.645518 ,   0.557621 ,\n",
       "          4.74576  ,  -0.579421 ,  -1.60146  ,  -3.69494  ,  -2.38239  ],\n",
       "       [ -2.73973  ,   0.418535 ,   1.1194   ,   0.829346 ,  -0.629111 ,\n",
       "          1.65094  ,   5.13709  ,   0.782524 ,  -1.65027  ,   0.443599 ,\n",
       "          0.610643 ,  -1.66774  ,  -0.821837 ,   1.42857  ,  -1.98333  ,\n",
       "          1.39114  ,  -0.126143 ,   2.01711  ,  -0.754243 ,   1.55945  ,\n",
       "          2.16181  ,  -1.79471  ,   3.22266  ,   3.19432  ,  -0.191022 ],\n",
       "       [  3.20354  ,   5.64811  ,  -1.45461  ,   3.26821  ,   3.25765  ,\n",
       "         -1.01104  ,  -2.55408  ,   2.22093  ,   2.40764  ,  -3.28757  ,\n",
       "          3.64805  ,   3.93495  ,  -3.45137  ,  -5.07571  ,  -4.99013  ,\n",
       "          0.858277 ,  -3.45495  ,   3.63705  ,   0.311526 ,   2.04864  ,\n",
       "          3.59929  ,  -0.688705 ,  -2.72745  ,  -4.0343   ,  -1.49745  ],\n",
       "       [ -4.5614   ,  -0.324675 ,  -2.60723  ,  -0.372578 ,   1.91805  ,\n",
       "         -1.92837  ,  -5.03704  ,  -0.13541  ,  -1.54278  ,   1.41044  ,\n",
       "         -0.661001 ,   1.79187  ,  -3.39893  ,  -0.404531 ,  -4.97051  ,\n",
       "          7.62174  ,   0.597015 ,  -2.22399  ,  -1.05116  ,  -6.05634  ,\n",
       "          4.23049  ,   2.88809  ,  -1.25174  ,  -2.85016  ,  -5.50398  ],\n",
       "       [  2.15023  ,   1.9153   ,  -0.295223 ,   2.75107  ,  -0.217687 ,\n",
       "          0.794777 ,   0.264901 ,   0.853759 ,   0.279799 ,  -0.774979 ,\n",
       "          1.83876  ,   0.247934 ,  -1.06832  ,  -2.73937  ,  -3.46789  ,\n",
       "         -2.98222  ,  -2.10226  ,  -1.83511  ,   0.0554631,   1.71849  ,\n",
       "          1.87991  ,  -0.36051  ,  -0.745033 ,  -0.0536481,  -1.21538  ],\n",
       "       [ -0.963597 ,   1.40845  ,  -1.88301  ,  -0.701481 ,   2.27179  ,\n",
       "          1.97562  ,  -3.13097  ,  -0.514706 ,  -2.70694  ,  -1.72216  ,\n",
       "          0.537857 ,  -1.97842  ,  -0.83682  ,  -0.269854 ,  -4.24679  ,\n",
       "          0.35461  ,   2.43615  ,   1.67331  ,  -2.77257  ,   1.74742  ,\n",
       "          0.       ,   1.96078  ,  -0.85885  ,  -2.9845   ,  -0.497159 ],\n",
       "       [  2.43855  ,   1.74769  ,   0.206113 ,   1.68998  ,  -0.593472 ,\n",
       "          0.       ,   1.69481  ,   0.401998 ,  -3.27004  ,   0.513614 ,\n",
       "          0.836897 ,  -0.140176 ,  -0.958971 ,  -1.8709   ,  -2.01259  ,\n",
       "          2.04082  ,  -0.225033 ,   2.21088  ,  -0.326435 ,   2.87998  ,\n",
       "          3.02802  ,   0.489097 ,  -0.788653 ,   0.908605 ,   3.79122  ],\n",
       "       [  0.658256 ,  -1.22308  ,   0.981194 ,   0.266951 ,   0.       ,\n",
       "          3.19785  ,   1.92256  ,   2.69549  ,  -2.49187  ,  -0.322061 ,\n",
       "          2.30388  ,   1.84783  ,  -3.06979  ,  -1.20192  ,  -4.28413  ,\n",
       "          5.0644   ,  -0.0533618,   0.265252 ,   0.188425 ,   3.11381  ,\n",
       "         -0.888769 ,  -2.32955  ,  -5.64885  ,   0.216626 ,   1.50125  ],\n",
       "       [ -1.99294  ,   1.79499  ,   0.581677 ,  -0.787219 ,   0.899149 ,\n",
       "         -1.52731  ,  -0.574713 ,   0.85668  ,  -3.30675  ,  -1.37836  ,\n",
       "         -0.713342 ,   6.39706  ,  -1.73558  ,  -0.943179 ,  -6.01432  ,\n",
       "          0.717765 ,  -2.58922  ,   3.17305  ,   1.23199  ,   3.64206  ,\n",
       "          4.27766  ,   4.531    ,   0.280177 ,  -4.15512  ,   1.71487  ],\n",
       "       [ -2.57967  ,   2.88523  ,   1.0501   ,   1.6372   ,  -0.898204 ,\n",
       "          0.0618716,   3.48275  ,  -0.771605 ,  -0.720839 ,  -0.822581 ,\n",
       "         -2.97628  ,   1.2197   ,  -1.00979  ,   0.0459841,  -1.35685  ,\n",
       "          1.75466  ,  -0.434293 ,  -0.628239 ,  -1.22611  ,  -0.131234 ,\n",
       "         -1.14996  ,   0.170834 ,  -1.39652  ,   2.97243  ,   0.39604  ],\n",
       "       [  1.63831  ,   0.354191 ,  -4.35294  ,   1.98482  ,   3.25815  ,\n",
       "         -3.72793  ,  -8.52713  ,  -0.632547 ,   1.00313  ,  -3.31725  ,\n",
       "          3.81731  ,   0.230814 ,  -4.0201   ,  -0.694847 ,  -4.8416   ,\n",
       "         -4.42849  ,   2.87026  ,   3.72861  ,  -1.36823  ,   4.33455  ,\n",
       "          5.93325  ,   3.79267  ,  -1.76678  ,  -0.34965  ,  -2.47066  ],\n",
       "       [  2.0447   ,   8.32943  ,  -0.428816 ,  -3.5225   ,  -3.09773  ,\n",
       "         -1.11993  ,  -1.59442  ,   2.35784  ,  -3.5334   ,  -3.78054  ,\n",
       "          0.0471921,   0.0919963,  -1.92661  ,   0.999131 ,  -3.20713  ,\n",
       "          1.78658  ,   1.1622   ,   9.88223  ,  -0.873563 ,   2.36181  ,\n",
       "          0.603248 ,  -1.66587  ,  -0.410023 ,   1.21055  ,  -0.998573 ],\n",
       "       [ -2.52731  ,  -1.68047  , -10.4975   ,  -3.39463  ,   3.87858  ,\n",
       "         -0.370054 ,  -1.10538  ,   0.454076 ,   0.0242072,  -2.72727  ,\n",
       "          0.316183 ,   1.94928  ,  -2.05613  ,   0.294913 ,  -3.13841  ,\n",
       "          3.09853  ,   0.123001 ,   2.57758  ,  -1.04505  ,   1.62485  ,\n",
       "          4.44836  ,   6.79773  , -10.2796   ,  -0.931601 ,   2.36238  ],\n",
       "       [  2.36505  ,   2.57463  ,  -0.575436 ,  -0.344102 ,  -0.364299 ,\n",
       "         -0.1701   ,   1.92234  ,   0.217155 ,  -1.58548  ,   0.631458 ,\n",
       "         -0.550285 ,  -0.677724 ,  -2.1166   ,  -0.108932 ,  -2.22303  ,\n",
       "          2.16216  ,   0.439686 ,   0.941974 ,   0.618357 ,   1.19853  ,\n",
       "         -0.744021 ,  -0.2766   ,  -3.82828  ,   1.36438  ,   1.12502  ],\n",
       "       [  1.35474  ,   1.53923  ,  -1.15869  ,   2.67542  ,   0.621118 ,\n",
       "          0.983069 ,  -0.988142 ,  -0.32543  ,  -3.55711  ,  -0.196078 ,\n",
       "         -2.01745  ,   2.6962   ,  -2.08445  ,  -3.33333  ,  -4.36992  ,\n",
       "          1.12843  ,  -2.60492  ,   0.91047  ,  -2.7685   ,   0.355691 ,\n",
       "          2.13612  ,  -0.3245   ,  -0.287356 ,  -0.400601 ,   4.00421  ],\n",
       "       [ -3.40829  ,   1.46723  ,   0.       ,   5.51344  ,   0.935484 ,\n",
       "          1.61823  ,  -0.325203 ,   0.598592 ,  -1.34181  ,   1.82469  ,\n",
       "         -0.717547 ,   1.78763  ,  -0.687398 ,  -1.07595  ,  -2.63659  ,\n",
       "         -0.385424 ,  -0.0975927,   0.854701 ,  -1.16814  ,   0.278067 ,\n",
       "          2.00584  ,  -2.7965   ,  -0.670904 ,   0.673077 ,  -0.770578 ],\n",
       "       [ -2.70668  ,   6.67656  ,   0.       ,   1.62876  ,  -1.25443  ,\n",
       "          1.02769  ,   2.46437  ,  -0.363967 ,  -1.81538  ,  -0.818182 ,\n",
       "         -2.09691  ,   0.394657 ,  -0.70028  ,  -0.137212 ,  -1.56636  ,\n",
       "         -8.13204  ,   0.989802 ,  -0.467836 ,   2.67081  ,   1.49579  ,\n",
       "         -1.20156  ,   2.92091  ,  -1.70992  ,   2.68624  ,  -0.498973 ],\n",
       "       [ -0.981997 ,   5.11278  ,  -0.71977  ,  -0.195886 ,   2.14739  ,\n",
       "          0.896414 ,  -0.0973236,   1.96599  ,   3.75321  ,  -0.86558  ,\n",
       "         -0.049776 ,  -2.28334  ,  -3.41018  ,  -2.79092  ,  -0.761905 ,\n",
       "          0.658617 ,  -0.437956 ,  -2.60827  ,   3.7467   ,   0.147638 ,\n",
       "          6.10225  ,   3.61582  ,  -0.105932 ,   1.89966  ,   0.0544959],\n",
       "       [  1.45776  ,   2.96552  ,  -1.08524  ,   1.87463  ,  -0.0925819,\n",
       "          1.98987  ,  -1.82353  ,  -0.0705302,  -0.718355 ,  -2.10767  ,\n",
       "         -0.0355619,   2.83645  ,  -0.277342 ,  -0.910807 ,  -4.32184  ,\n",
       "          1.03488  ,  -0.992295 ,   5.44794  ,  -0.86145  ,   2.73063  ,\n",
       "          0.880196 ,  -0.138906 ,  -1.38396  ,   0.112511 ,   1.16044  ],\n",
       "       [  0.177552 ,   1.95851  ,   1.68287  ,   0.97782  ,   3.00424  ,\n",
       "         -1.225    ,  -1.93136  ,   3.04878  ,  -1.00404  ,  -4.33364  ,\n",
       "         -2.37762  ,  -0.754943 ,  -1.42098  ,  -6.14075  ,  -2.52161  ,\n",
       "          3.60708  ,   2.0057   ,   3.91048  ,  -0.919995 ,   2.13754  ,\n",
       "          4.2042   ,   2.53663  ,   0.435448 ,  -2.578    ,   1.52976  ],\n",
       "       [  1.21509  ,   3.19635  ,  -0.431862 ,   1.04925  ,  -0.356333 ,\n",
       "         -2.02977  ,  -0.0835422,   3.53501  ,  -0.701214 ,  -0.641242 ,\n",
       "         -1.54594  ,   2.91347  ,  -3.48818  ,  -0.204531 ,  -1.24294  ,\n",
       "          2.84262  ,  -0.417851 ,   3.37154  ,  -0.704698 ,   0.924025 ,\n",
       "          2.86687  ,  -4.92066  ,  -1.65016  ,  -1.42338  ,   0.695716 ],\n",
       "       [ -1.48197  ,   2.19485  ,   0.372353 ,   0.542299 ,   0.919811 ,\n",
       "         -1.18673  ,  -4.48936  ,   4.34783  ,   0.704535 ,   0.263043 ,\n",
       "         -2.49383  ,   4.06704  ,  -0.121655 ,  -1.95908  ,  -3.86216  ,\n",
       "          3.79015  ,   1.56114  ,   0.926135 ,  -2.75582  ,  -0.907519 ,\n",
       "          0.405314 ,   1.48837  ,  -1.10169  ,  -3.57542  ,   0.599733 ],\n",
       "       [ -1.3064   ,   1.50356  ,   2.34958  ,   0.582396 ,   0.110389 ,\n",
       "          2.59853  ,   1.61523  ,   0.0788747,  -4.08673  ,   0.458235 ,\n",
       "         -0.58309  ,   2.71145  ,  -0.297767 ,   0.382653 ,  -1.93596  ,\n",
       "         -0.255892 ,  -0.35382  ,   0.0260112,   2.03999  ,   2.38095  ,\n",
       "          0.338753 ,  -3.54086  ,  -1.98815  ,   1.61087  ,   0.482251 ],\n",
       "       [ -1.04979  ,  -0.721118 ,   0.293686 ,   3.09816  ,  -1.59787  ,\n",
       "          0.798771 ,   1.13011  ,   1.38213  ,  -2.54896  ,  -0.780772 ,\n",
       "         -0.673092 ,   1.43609  ,  -0.183178 ,  -1.26919  ,  -2.10636  ,\n",
       "          0.685805 ,   0.0743826,   0.458783 ,   1.62069  ,   3.31063  ,\n",
       "          0.385109 ,  -4.49302  ,   1.49937  ,   1.97427  ,  -0.696092 ],\n",
       "       [ -1.98408  ,   3.514    ,  -2.07243  ,   0.768232 ,   1.27858  ,\n",
       "          0.702216 ,  -0.822737 ,   1.35194  ,  -2.44491  ,  -1.04774  ,\n",
       "         -0.579742 ,   4.11705  ,   0.387254 ,  -2.0291   ,  -3.56194  ,\n",
       "          2.80047  ,   0.58265  ,   2.15358  ,   0.31556  ,   2.21558  ,\n",
       "          0.409417 ,  -0.599424 ,  -2.67443  ,   0.745016 ,   1.65073  ],\n",
       "       [ -4.07609  ,   3.25216  ,  -1.08417  ,   0.8647   ,   2.42368  ,\n",
       "         -0.0452352,   1.71313  ,   0.692042 ,  -1.54648  ,  -2.2917   ,\n",
       "         -1.54358  ,  -0.295664 ,   0.333991 ,  -0.986044 ,  -1.81251  ,\n",
       "          0.417402 ,  -0.0672269,   5.98842  ,   1.88553  ,   0.528379 ,\n",
       "          1.13032  ,  -0.0479004,  -1.71391  ,   2.31915  ,   0.723356 ]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T10:17:45.054Z",
     "start_time": "2024-11-05T10:17:44.976869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(init='random', n_clusters=8)\n",
    "kmeans.fit(price_changes)\n"
   ],
   "id": "9eb0df81e9d4ffaf",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19928\\.conda\\envs\\dm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(init='random')"
      ],
      "text/html": [
       "<style>#sk-container-id-8 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-8 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-8 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-8 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-8 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-8 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-8 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(init=&#x27;random&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;KMeans<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.cluster.KMeans.html\">?<span>Documentation for KMeans</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>KMeans(init=&#x27;random&#x27;)</pre></div> </div></div></div></div>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<p style=\"font-size:20px;\">\n",
    "Shows for each data points its cluster.\n",
    "</p>"
   ],
   "id": "453745a32b2fe93a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T11:30:44.133818Z",
     "start_time": "2024-11-05T11:30:44.128287Z"
    }
   },
   "cell_type": "code",
   "source": "kmeans.labels_, kmeans.cluster_centers_, kmeans.n_iter_\n",
   "id": "3f927d10bab4ded2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 1, 0, 3, 4, 5, 4, 2, 5, 1, 1, 1, 1, 5, 4, 7, 6, 1, 1, 5, 5, 0,\n",
       "        1, 0, 1, 1, 5, 5, 1, 1], dtype=int32),\n",
       " array([[ -0.45276167,   2.99973333,   0.497452  ,   0.862148  ,\n",
       "           2.40279667,  -0.39941267,  -1.73934787,   2.7955    ,\n",
       "           2.14000333,  -3.07447333,  -1.13949867,  -1.29716333,\n",
       "          -2.01673   ,  -4.98672333,  -2.24480833,   2.11092233,\n",
       "           0.872748  ,   1.44407333,   1.42131167,   1.698886  ,\n",
       "           4.59336   ,   1.879895  ,   1.07392867,  -0.50375667,\n",
       "           0.82935497],\n",
       "        [ -0.68975623,   2.50959692,  -0.30901777,   0.63056008,\n",
       "           0.64237339,   0.50161768,  -0.4863914 ,   0.90291337,\n",
       "          -1.83279615,  -0.56041832,  -0.72864611,   2.24029046,\n",
       "          -1.50509485,  -1.03314131,  -3.52789692,   2.14831131,\n",
       "          -0.02605021,   2.580847  ,  -0.53053835,   1.89575738,\n",
       "           1.21996823,   0.5509682 ,  -1.75866081,  -0.643416  ,\n",
       "           1.35087855],\n",
       "        [ -4.5614    ,  -0.324675  ,  -2.60723   ,  -0.372578  ,\n",
       "           1.91805   ,  -1.92837   ,  -5.03704   ,  -0.13541   ,\n",
       "          -1.54278   ,   1.41044   ,  -0.661001  ,   1.79187   ,\n",
       "          -3.39893   ,  -0.404531  ,  -4.97051   ,   7.62174   ,\n",
       "           0.597015  ,  -2.22399   ,  -1.05116   ,  -6.05634   ,\n",
       "           4.23049   ,   2.88809   ,  -1.25174   ,  -2.85016   ,\n",
       "          -5.50398   ],\n",
       "        [  0.431862  ,   3.48494   ,  -1.72414   ,  -1.84332   ,\n",
       "           0.304692  ,  -1.12285   ,  -3.83964   ,   0.0530786 ,\n",
       "          -3.76193   ,  -2.23312   ,  -0.0669344 , -15.4229    ,\n",
       "          -5.73566   ,   0.285551  ,  -3.49608   ,   1.2894    ,\n",
       "           3.76249   ,   0.35545   ,  -1.18153   ,  -0.346021  ,\n",
       "           5.35117   ,   2.54279   ,  -0.480513  ,  -3.70793   ,\n",
       "          -2.35627   ],\n",
       "        [  2.88700333,   2.65917367,  -1.93585   ,   2.41632   ,\n",
       "           2.69367333,  -1.88613933,  -4.03037667,   1.47239433,\n",
       "           1.017831  ,  -2.94097667,   4.14502   ,   2.63019467,\n",
       "          -2.83509   ,  -2.98106233,  -5.0887    ,  -0.15487433,\n",
       "          -0.25495667,   3.45620333,  -0.56740733,   2.31360367,\n",
       "           4.75943333,   0.84151467,  -2.03189667,  -2.69296333,\n",
       "          -2.11683333],\n",
       "        [ -1.66290429,   2.02075671,   0.64536329,   2.29148171,\n",
       "          -0.507347  ,   1.22154423,   1.96703543,   0.36575824,\n",
       "          -1.69774143,  -0.06714143,  -0.656788  ,   0.87567443,\n",
       "          -0.68122429,  -0.48064499,  -2.15047714,  -1.13199586,\n",
       "          -0.2928463 ,   0.06077431,   0.46263716,   1.51602043,\n",
       "           0.63141457,  -1.413408  ,  -0.25549957,   1.86536556,\n",
       "          -0.35625057],\n",
       "        [ -2.52731   ,  -1.68047   , -10.4975    ,  -3.39463   ,\n",
       "           3.87858   ,  -0.370054  ,  -1.10538   ,   0.454076  ,\n",
       "           0.0242072 ,  -2.72727   ,   0.316183  ,   1.94928   ,\n",
       "          -2.05613   ,   0.294913  ,  -3.13841   ,   3.09853   ,\n",
       "           0.123001  ,   2.57758   ,  -1.04505   ,   1.62485   ,\n",
       "           4.44836   ,   6.79773   , -10.2796    ,  -0.931601  ,\n",
       "           2.36238   ],\n",
       "        [  2.0447    ,   8.32943   ,  -0.428816  ,  -3.5225    ,\n",
       "          -3.09773   ,  -1.11993   ,  -1.59442   ,   2.35784   ,\n",
       "          -3.5334    ,  -3.78054   ,   0.0471921 ,   0.0919963 ,\n",
       "          -1.92661   ,   0.999131  ,  -3.20713   ,   1.78658   ,\n",
       "           1.1622    ,   9.88223   ,  -0.873563  ,   2.36181   ,\n",
       "           0.603248  ,  -1.66587   ,  -0.410023  ,   1.21055   ,\n",
       "          -0.998573  ]]),\n",
       " 4)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T10:17:50.269506Z",
     "start_time": "2024-11-05T10:17:50.266937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# SSE\n",
    "sse = kmeans.inertia_\n",
    "print(\"Sum of Squared Errors (SSE):\", sse)"
   ],
   "id": "1aff443fd38f5dad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of Squared Errors (SSE): 1685.7398582935516\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<p style=\"font-size:20px;\">\n",
    "So here, We only run a most simply K-means method with init='random' and K=8. And We get the centroids (centers) and the cluster of each data points.<br>\n",
    "And also, We get the SSE=1685.7398582935516\n",
    "</p>"
   ],
   "id": "4268fd62747c32d6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T11:38:05.501583Z",
     "start_time": "2024-11-05T11:38:05.494482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Silhouette Score\n",
    "labels = kmeans.labels_\n",
    "silhouette_avg = silhouette_score(price_changes, labels)\n",
    "print(f'Silhouette Score: {silhouette_avg:.3f}')\n"
   ],
   "id": "d0a0e75a852fa1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.095\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<p style=\"font-size:20px;\">\n",
    "Through the Silhouette Score evaluation, we found that the most simple K-means clustering effect is not so good.\n",
    "</p>"
   ],
   "id": "f82193a9a713c5ff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Question 2\n",
    "<p style=\"font-size:22px;\">\n",
    "Change the parameters and decrease the SSE as much as possible.\n",
    "</p>"
   ],
   "id": "be1ae992fa626c03"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<p style=\"font-size:20px;\">\n",
    "Due to the wording of the question, it is recommended that we choose K=8, which means there are a total of 8 clusters. Therefore, we can modify a total of four parameters, namely:<br><br>\n",
    "The K-means method (init), <br>\n",
    "Maximum iteration count (max_iter), <br>\n",
    "Initialization repetition count (n_init), <br>\n",
    "Convergence tolerance (tol)<br>\n",
    "</p>"
   ],
   "id": "1eda3d883a96e777"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T12:14:56.535897Z",
     "start_time": "2024-11-05T12:14:49.150836Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "# set the range of the method and the parameters\n",
    "init_methods = ['random', 'k-means++']\n",
    "n_init_values = [10, 50, 100]\n",
    "max_iter_values = [2, 3, 4]\n",
    "tol_values = [1e-4, 1e-16]\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "# generate all parameters group\n",
    "for init, n_init, max_iter, tol in product(init_methods, n_init_values, max_iter_values, tol_values):\n",
    "    \n",
    "    if max_iter in max_iter_values or tol in tol_values:\n",
    "        \n",
    "        kmeans = KMeans(\n",
    "            n_clusters=8,\n",
    "            init=init,\n",
    "            n_init=n_init,\n",
    "            max_iter=max_iter,\n",
    "            tol=tol,\n",
    "            random_state=520\n",
    "        )\n",
    "    else:\n",
    "        kmeans = KMeans(\n",
    "            n_clusters=8,\n",
    "            init=init,\n",
    "            n_init=n_init,\n",
    "            max_iter=max_iter,\n",
    "            tol=tol\n",
    "        )\n",
    "    kmeans.fit(price_changes)\n",
    "    \n",
    "    sse = kmeans.inertia_\n",
    "    \n",
    "    results.append({\n",
    "        'init': init,\n",
    "        'n_init': n_init,\n",
    "        'max_iter': max_iter,\n",
    "        'tol': tol,\n",
    "        'SSE': sse\n",
    "    })\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# sort and index and show\n",
    "results_df.sort_values(by='SSE', ascending=True, inplace=True)\n",
    "results_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "results_df\n"
   ],
   "id": "78e46929e6f2d44a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19928\\.conda\\envs\\dm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\19928\\.conda\\envs\\dm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\19928\\.conda\\envs\\dm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\19928\\.conda\\envs\\dm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\19928\\.conda\\envs\\dm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\19928\\.conda\\envs\\dm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\19928\\.conda\\envs\\dm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\19928\\.conda\\envs\\dm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\19928\\.conda\\envs\\dm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\19928\\.conda\\envs\\dm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\19928\\.conda\\envs\\dm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\19928\\.conda\\envs\\dm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\19928\\.conda\\envs\\dm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\19928\\.conda\\envs\\dm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\19928\\.conda\\envs\\dm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\19928\\.conda\\envs\\dm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\19928\\.conda\\envs\\dm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\19928\\.conda\\envs\\dm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\19928\\.conda\\envs\\dm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\19928\\.conda\\envs\\dm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\19928\\.conda\\envs\\dm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\19928\\.conda\\envs\\dm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\19928\\.conda\\envs\\dm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\19928\\.conda\\envs\\dm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\19928\\.conda\\envs\\dm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\19928\\.conda\\envs\\dm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\19928\\.conda\\envs\\dm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\19928\\.conda\\envs\\dm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\19928\\.conda\\envs\\dm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\19928\\.conda\\envs\\dm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\19928\\.conda\\envs\\dm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\19928\\.conda\\envs\\dm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\19928\\.conda\\envs\\dm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\19928\\.conda\\envs\\dm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\19928\\.conda\\envs\\dm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\19928\\.conda\\envs\\dm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         init  n_init  max_iter           tol          SSE\n",
       "0   k-means++     100         4  1.000000e-16  1527.455307\n",
       "1   k-means++     100         4  1.000000e-04  1527.455307\n",
       "2   k-means++     100         3  1.000000e-16  1527.455307\n",
       "3   k-means++     100         3  1.000000e-04  1527.455307\n",
       "4   k-means++      50         2  1.000000e-04  1537.246760\n",
       "5   k-means++      50         2  1.000000e-16  1537.246760\n",
       "6   k-means++      50         3  1.000000e-04  1537.246760\n",
       "7   k-means++      50         3  1.000000e-16  1537.246760\n",
       "8   k-means++      50         4  1.000000e-04  1537.246760\n",
       "9   k-means++      50         4  1.000000e-16  1537.246760\n",
       "10  k-means++     100         2  1.000000e-04  1537.246760\n",
       "11  k-means++     100         2  1.000000e-16  1537.246760\n",
       "12  k-means++      10         4  1.000000e-16  1542.844075\n",
       "13  k-means++      10         4  1.000000e-04  1542.844075\n",
       "14  k-means++      10         3  1.000000e-16  1542.844075\n",
       "15  k-means++      10         3  1.000000e-04  1542.844075\n",
       "16  k-means++      10         2  1.000000e-04  1555.632869\n",
       "17  k-means++      10         2  1.000000e-16  1555.632869\n",
       "18     random      50         3  1.000000e-04  1620.131890\n",
       "19     random      50         3  1.000000e-16  1620.131890\n",
       "20     random     100         3  1.000000e-16  1620.131890\n",
       "21     random     100         3  1.000000e-04  1620.131890\n",
       "22     random      50         4  1.000000e-16  1620.131890\n",
       "23     random      50         4  1.000000e-04  1620.131890\n",
       "24     random     100         4  1.000000e-16  1620.131890\n",
       "25     random     100         4  1.000000e-04  1620.131890\n",
       "26     random      50         2  1.000000e-16  1643.294207\n",
       "27     random      50         2  1.000000e-04  1643.294207\n",
       "28     random     100         2  1.000000e-04  1643.294207\n",
       "29     random     100         2  1.000000e-16  1643.294207\n",
       "30     random      10         3  1.000000e-16  1716.867150\n",
       "31     random      10         3  1.000000e-04  1716.867150\n",
       "32     random      10         4  1.000000e-04  1716.867150\n",
       "33     random      10         4  1.000000e-16  1716.867150\n",
       "34     random      10         2  1.000000e-16  1728.472629\n",
       "35     random      10         2  1.000000e-04  1728.472629"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>init</th>\n",
       "      <th>n_init</th>\n",
       "      <th>max_iter</th>\n",
       "      <th>tol</th>\n",
       "      <th>SSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k-means++</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000e-16</td>\n",
       "      <td>1527.455307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k-means++</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>1527.455307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k-means++</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000e-16</td>\n",
       "      <td>1527.455307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k-means++</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>1527.455307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k-means++</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>1537.246760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>k-means++</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000e-16</td>\n",
       "      <td>1537.246760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>k-means++</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>1537.246760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>k-means++</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000e-16</td>\n",
       "      <td>1537.246760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>k-means++</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>1537.246760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>k-means++</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000e-16</td>\n",
       "      <td>1537.246760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>k-means++</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>1537.246760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>k-means++</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000e-16</td>\n",
       "      <td>1537.246760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>k-means++</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000e-16</td>\n",
       "      <td>1542.844075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>k-means++</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>1542.844075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>k-means++</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000e-16</td>\n",
       "      <td>1542.844075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>k-means++</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>1542.844075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>k-means++</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>1555.632869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>k-means++</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000e-16</td>\n",
       "      <td>1555.632869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>random</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>1620.131890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>random</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000e-16</td>\n",
       "      <td>1620.131890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>random</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000e-16</td>\n",
       "      <td>1620.131890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>random</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>1620.131890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>random</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000e-16</td>\n",
       "      <td>1620.131890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>random</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>1620.131890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>random</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000e-16</td>\n",
       "      <td>1620.131890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>random</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>1620.131890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>random</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000e-16</td>\n",
       "      <td>1643.294207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>random</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>1643.294207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>random</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>1643.294207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>random</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000e-16</td>\n",
       "      <td>1643.294207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>random</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000e-16</td>\n",
       "      <td>1716.867150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>random</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>1716.867150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>random</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>1716.867150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>random</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000e-16</td>\n",
       "      <td>1716.867150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>random</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000e-16</td>\n",
       "      <td>1728.472629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>random</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>1728.472629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<p style=\"font-size:20px;\">\n",
    "Here, we find that, the K-means++ method always better than the initial K-means method. However, this does not mean that K-means++will always be better than the K-means method. Because the K-means++method only increases the probability of selecting points with initial distance as centroids, it can achieve better performance than ordinary K-means methods in most cases. However, there is still a situation where the K-means method selects the most suitable centroid at a certain time, which the K-means++method does not have.<br><br>\n",
    "And then, we can mining more infomation of the trend.\n",
    "</p>"
   ],
   "id": "47d625ad2ea21e1b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<p style=\"font-size:20px;\">\n",
    "Here, we set three parameters fixed, and the last remaining parameter is variable, so we can see how SSE changes with the variation of different parameters.\n",
    "</p>"
   ],
   "id": "6e67b46d5db31e93"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T12:14:58.995412Z",
     "start_time": "2024-11-05T12:14:58.957334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def view_all_sse_by_varying_parameters(results_df):\n",
    "\n",
    "    fixed_init = 'k-means++'\n",
    "    \n",
    "    param_names = ['n_init', 'max_iter', 'tol']\n",
    "    \n",
    "    all_results = {}\n",
    "    \n",
    "    # 3 fixed, 1 changed\n",
    "    for fixed_params in combinations(param_names, 2):\n",
    "        \n",
    "        # changed parameters\n",
    "        varying_param = [param for param in param_names if param not in fixed_params][0]\n",
    "        \n",
    "        # fixed parameters group\n",
    "        fixed_param_combinations = results_df[(results_df['init'] == fixed_init)][list(fixed_params)].drop_duplicates()\n",
    "        \n",
    "        # all groups\n",
    "        for _, fixed_values in fixed_param_combinations.iterrows():\n",
    "\n",
    "            fixed_params_dict = dict(zip(fixed_params, fixed_values))\n",
    "            fixed_params_dict['init'] = fixed_init\n",
    "            \n",
    "            filtered_results = results_df.copy()\n",
    "            for param, value in fixed_params_dict.items():\n",
    "                filtered_results = filtered_results[filtered_results[param] == value]\n",
    "            \n",
    "            filtered_results = filtered_results[[varying_param, 'SSE']].sort_values(by=varying_param)\n",
    "            filtered_results.reset_index(drop=True, inplace=True)\n",
    "            \n",
    "            key = f\"fixed parameters: {fixed_params_dict}, changed parameters: {varying_param}\"\n",
    "            all_results[key] = filtered_results\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "all_sse_results = view_all_sse_by_varying_parameters(results_df)\n",
    "\n",
    "for key, df in all_sse_results.items():\n",
    "    print(f\"\\n{key}\\n\")\n",
    "    print(df)\n"
   ],
   "id": "4b8c79968bc47645",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fixed parameters: {'n_init': 100, 'max_iter': 4, 'init': 'k-means++'}, changed parameters: tol\n",
      "\n",
      "            tol          SSE\n",
      "0  1.000000e-16  1527.455307\n",
      "1  1.000000e-04  1527.455307\n",
      "\n",
      "fixed parameters: {'n_init': 100, 'max_iter': 3, 'init': 'k-means++'}, changed parameters: tol\n",
      "\n",
      "            tol          SSE\n",
      "0  1.000000e-16  1527.455307\n",
      "1  1.000000e-04  1527.455307\n",
      "\n",
      "fixed parameters: {'n_init': 50, 'max_iter': 2, 'init': 'k-means++'}, changed parameters: tol\n",
      "\n",
      "            tol         SSE\n",
      "0  1.000000e-16  1537.24676\n",
      "1  1.000000e-04  1537.24676\n",
      "\n",
      "fixed parameters: {'n_init': 50, 'max_iter': 3, 'init': 'k-means++'}, changed parameters: tol\n",
      "\n",
      "            tol         SSE\n",
      "0  1.000000e-16  1537.24676\n",
      "1  1.000000e-04  1537.24676\n",
      "\n",
      "fixed parameters: {'n_init': 50, 'max_iter': 4, 'init': 'k-means++'}, changed parameters: tol\n",
      "\n",
      "            tol         SSE\n",
      "0  1.000000e-16  1537.24676\n",
      "1  1.000000e-04  1537.24676\n",
      "\n",
      "fixed parameters: {'n_init': 100, 'max_iter': 2, 'init': 'k-means++'}, changed parameters: tol\n",
      "\n",
      "            tol         SSE\n",
      "0  1.000000e-16  1537.24676\n",
      "1  1.000000e-04  1537.24676\n",
      "\n",
      "fixed parameters: {'n_init': 10, 'max_iter': 4, 'init': 'k-means++'}, changed parameters: tol\n",
      "\n",
      "            tol          SSE\n",
      "0  1.000000e-16  1542.844075\n",
      "1  1.000000e-04  1542.844075\n",
      "\n",
      "fixed parameters: {'n_init': 10, 'max_iter': 3, 'init': 'k-means++'}, changed parameters: tol\n",
      "\n",
      "            tol          SSE\n",
      "0  1.000000e-16  1542.844075\n",
      "1  1.000000e-04  1542.844075\n",
      "\n",
      "fixed parameters: {'n_init': 10, 'max_iter': 2, 'init': 'k-means++'}, changed parameters: tol\n",
      "\n",
      "            tol          SSE\n",
      "0  1.000000e-16  1555.632869\n",
      "1  1.000000e-04  1555.632869\n",
      "\n",
      "fixed parameters: {'n_init': 100.0, 'tol': 1e-16, 'init': 'k-means++'}, changed parameters: max_iter\n",
      "\n",
      "   max_iter          SSE\n",
      "0         2  1537.246760\n",
      "1         3  1527.455307\n",
      "2         4  1527.455307\n",
      "\n",
      "fixed parameters: {'n_init': 100.0, 'tol': 0.0001, 'init': 'k-means++'}, changed parameters: max_iter\n",
      "\n",
      "   max_iter          SSE\n",
      "0         2  1537.246760\n",
      "1         3  1527.455307\n",
      "2         4  1527.455307\n",
      "\n",
      "fixed parameters: {'n_init': 50.0, 'tol': 0.0001, 'init': 'k-means++'}, changed parameters: max_iter\n",
      "\n",
      "   max_iter         SSE\n",
      "0         2  1537.24676\n",
      "1         3  1537.24676\n",
      "2         4  1537.24676\n",
      "\n",
      "fixed parameters: {'n_init': 50.0, 'tol': 1e-16, 'init': 'k-means++'}, changed parameters: max_iter\n",
      "\n",
      "   max_iter         SSE\n",
      "0         2  1537.24676\n",
      "1         3  1537.24676\n",
      "2         4  1537.24676\n",
      "\n",
      "fixed parameters: {'n_init': 10.0, 'tol': 1e-16, 'init': 'k-means++'}, changed parameters: max_iter\n",
      "\n",
      "   max_iter          SSE\n",
      "0         2  1555.632869\n",
      "1         3  1542.844075\n",
      "2         4  1542.844075\n",
      "\n",
      "fixed parameters: {'n_init': 10.0, 'tol': 0.0001, 'init': 'k-means++'}, changed parameters: max_iter\n",
      "\n",
      "   max_iter          SSE\n",
      "0         2  1555.632869\n",
      "1         3  1542.844075\n",
      "2         4  1542.844075\n",
      "\n",
      "fixed parameters: {'max_iter': 4.0, 'tol': 1e-16, 'init': 'k-means++'}, changed parameters: n_init\n",
      "\n",
      "   n_init          SSE\n",
      "0      10  1542.844075\n",
      "1      50  1537.246760\n",
      "2     100  1527.455307\n",
      "\n",
      "fixed parameters: {'max_iter': 4.0, 'tol': 0.0001, 'init': 'k-means++'}, changed parameters: n_init\n",
      "\n",
      "   n_init          SSE\n",
      "0      10  1542.844075\n",
      "1      50  1537.246760\n",
      "2     100  1527.455307\n",
      "\n",
      "fixed parameters: {'max_iter': 3.0, 'tol': 1e-16, 'init': 'k-means++'}, changed parameters: n_init\n",
      "\n",
      "   n_init          SSE\n",
      "0      10  1542.844075\n",
      "1      50  1537.246760\n",
      "2     100  1527.455307\n",
      "\n",
      "fixed parameters: {'max_iter': 3.0, 'tol': 0.0001, 'init': 'k-means++'}, changed parameters: n_init\n",
      "\n",
      "   n_init          SSE\n",
      "0      10  1542.844075\n",
      "1      50  1537.246760\n",
      "2     100  1527.455307\n",
      "\n",
      "fixed parameters: {'max_iter': 2.0, 'tol': 0.0001, 'init': 'k-means++'}, changed parameters: n_init\n",
      "\n",
      "   n_init          SSE\n",
      "0      10  1555.632869\n",
      "1      50  1537.246760\n",
      "2     100  1537.246760\n",
      "\n",
      "fixed parameters: {'max_iter': 2.0, 'tol': 1e-16, 'init': 'k-means++'}, changed parameters: n_init\n",
      "\n",
      "   n_init          SSE\n",
      "0      10  1555.632869\n",
      "1      50  1537.246760\n",
      "2     100  1537.246760\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<p style=\"font-size:20px;\">\n",
    "From the results, it can be seen that:<br><br>\n",
    " As the maximum number of iterations (max_iter) increases, SSE decreases and stops at the end of the algorithm. That is to say, when the algorithm is not converging, it will decrease with the increase of max_iter, because the increase in the maximum number of iterations means a more suitable calculation of the centroid when the algorithm is not converging. But once the algorithm has converged within max_iter, SSE will not increase with the increase of max_iter, because the algorithm has already converged within the maximum number of iterations and has not reached the maximum number of iterations, that is, max_iter will not affect the number of iterations of the algorithm.<br><br>\n",
    " As the number of initialization iterations (n_init) increases, SSE may decrease. Because the K-means algorithm selects the cluster with the best value, i.e., the cluster with the smallest SSE, among the initialization steps of n2, as the result output, an increase in n2 implies a greater likelihood of finding a better cluster. However, this does not necessarily mean that an increase in n_inite will lead to a decrease in SSE, as the algorithm may not be able to find a better clustering solution within a larger number of initialization attempts. This can result in SSE not increasing as n_inite increases.<br><br>\n",
    " Here, SSE does not decrease with the decrease of the minimum threshold (tol) for centroid change. This may be because within the iteration times, the centroids of the 8 clusters are no longer changing, or the changes are very, very small. This will result in changes in tol not affecting the iteration times of the algorithm, nor will it affect the value of SSE.However, under normal circumstances, smaller convergence conditions lead to more iterations, resulting in smaller SSE.\n",
    "</p>"
   ],
   "id": "8efa23ecb6b4d5e0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Question 3\n",
    "<p style=\"font-size:22px;\">\n",
    "try to label each cluster with a topic.\n",
    "</p>"
   ],
   "id": "541be9c12405cf80"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T12:46:27.326973Z",
     "start_time": "2024-11-05T12:45:46.209086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=8, init='k-means++', n_init=10000, max_iter=100)\n",
    "kmeans.fit(price_changes)\n",
    "\n",
    "# SSE\n",
    "sse = kmeans.inertia_\n",
    "print(\"Sum of Squared Errors (SSE):\", sse)"
   ],
   "id": "8e8ba81bf12da245",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19928\\.conda\\envs\\dm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of Squared Errors (SSE): 1508.434119398986\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T12:53:46.856020Z",
     "start_time": "2024-11-05T12:53:46.848382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "labels = kmeans.labels_\n",
    "\n",
    "stock_clusters = pd.DataFrame({'Stock': data['StockName'], 'Cluster': labels})\n",
    "\n",
    "for cluster in range(kmeans.n_clusters):\n",
    "    print(f\"\\nCluster {cluster}:\")\n",
    "    stocks_in_cluster = stock_clusters[stock_clusters['Cluster'] == cluster]['Stock'].values\n",
    "    print(stocks_in_cluster)\n"
   ],
   "id": "59e856ba5a83ebef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster 0:\n",
      "['IBM' 'The Home Depot' 'Intel' 'Wal-Mart' 'General Electric'\n",
      " 'United Technologies' 'Travelers' '3M']\n",
      "\n",
      "Cluster 1:\n",
      "['American Express' 'Boeing' 'Microsoft' 'Walt Disney' 'JPMorgan Chase']\n",
      "\n",
      "Cluster 2:\n",
      "['Bank of America']\n",
      "\n",
      "Cluster 3:\n",
      "['Kraft' 'Verizon' 'Procter & Gamble' 'AT&T' 'Merck' 'McDonalds'\n",
      " 'Coca-Cola' 'Johnson & Johnson']\n",
      "\n",
      "Cluster 4:\n",
      "['Cisco Systems']\n",
      "\n",
      "Cluster 5:\n",
      "['Hewlett-Packard']\n",
      "\n",
      "Cluster 6:\n",
      "['Chevron' 'Pfizer' 'ExxonMobil']\n",
      "\n",
      "Cluster 7:\n",
      "['DuPont' 'Caterpillar' 'Alcoa']\n"
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Cluster 1:\n",
    "<p style=\"font-size:16px;\">\n",
    "Contains: American Express, Boeing, Microsoft, Walt Disney, and JPMorgan Chase.\n",
    "This cluster includes companies from finance, industrials, information technology, and communication services, representing major global companies.<br><br>\n",
    " So this cluster can be labeled as the “Large Multinational Corporation Stocks.”<br><br>\n",
    "</p>\n",
    "\n",
    "### Cluster 2:\n",
    "<p style=\"font-size:16px;\">\n",
    "Contains: Bank of America.<br><br>\n",
    "So this cluster can be labeled as the “Financial Stocks.”<br><br>\n",
    "</p>\n",
    "\n",
    "### Cluster 3:\n",
    "<p style=\"font-size:16px;\">\n",
    "Contains: Kraft, Verizon, Procter & Gamble, AT&T, Merck, McDonald’s, Coca-Cola, and Johnson & Johnson.\n",
    "These companies span consumer staples, communication services, healthcare, and discretionary consumption, and most of which are well-known consumer brands.<br><br>\n",
    "So this cluster can be labeled as the “Consumer Stocks.”<br><br>\n",
    "</p>\n",
    "\n",
    "### Cluster 4:\n",
    "<p style=\"font-size:16px;\">\n",
    "Contains: Cisco Systems.<br><br>\n",
    "So this cluster can be labeled as the “Information Technology Stocks.”<br><br>\n",
    "</p>\n",
    "\n",
    "### Cluster 5:\n",
    "<p style=\"font-size:16px;\">\n",
    "Contains: Hewlett-Packard.<br><br>\n",
    "So this cluster can also be labeled as the “Information Technology Stocks.”<br><br>\n",
    "</p>\n",
    "\n",
    "### Cluster 6:\n",
    "<p style=\"font-size:16px;\">\n",
    "Contains: Chevron, Pfizer, and ExxonMobil.\n",
    "This cluster consists of companies in the energy and healthcare sectors and more in Energy.<br><br>\n",
    "So this cluster can be labeled as the “Energy Stocks.”<br><br>\n",
    "</p>\n",
    "\n",
    "### Cluster 7:\n",
    "<p style=\"font-size:16px;\">\n",
    "Contains: DuPont, Caterpillar, and Alcoa.\n",
    "These stocks belong primarily to the materials and industrials sectors and more in Materials.<br><br>\n",
    "So this cluster can be labeled as the “Materials Stocks.”<br><br>\n",
    "</p>\n"
   ],
   "id": "d8748b7bfecedd6f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
